{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T09:19:44.517465Z",
     "start_time": "2018-12-01T09:19:35.469219Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "from keras.layers import Dense, Embedding, Input, SimpleRNN, LSTM, Bidirectional\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:14.164419Z",
     "start_time": "2018-01-17T13:41:13.463438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/input/train.csv\")\n",
    "targets = [\n",
    "    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n",
    "]\n",
    "X_train = df_train.comment_text\n",
    "y_train = df_train[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:15.924168Z",
     "start_time": "2018-01-17T13:41:14.167636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/input/test.csv\")\n",
    "df_test.loc[df_test.comment_text.isnull(), \"comment_text\"] = \"\"\n",
    "X_test = df_test.comment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:15.928944Z",
     "start_time": "2018-01-17T13:41:15.925794Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "max_features = 20000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T11:12:14.547055Z",
     "start_time": "2017-12-26T11:12:12.543572Z"
    },
    "collapsed": true
   },
   "source": [
    "# Preprocessing : Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:16.598800Z",
     "start_time": "2018-01-17T13:41:15.930905Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.map(lambda x : len(x.split(\" \"))).hist(bins=100)\n",
    "plt.vlines(100, ymin=0, ymax=2000, colors=\"red\")\n",
    "plt.title(\"Comment length (number of words)\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:43.235073Z",
     "start_time": "2018-01-17T13:41:16.601228Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:43.277422Z",
     "start_time": "2018-01-17T13:41:43.236963Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "\n",
    "def get_embedding_matrix(tokenizer, path_glove, embed_size,\n",
    "                         max_features=20000):\n",
    "    embeddings_index = dict(\n",
    "        get_coefs(*o.strip().split()) for o in open(path_glove))\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words,\n",
    "                                                            embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:50.523524Z",
     "start_time": "2018-01-17T13:41:43.281880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_path = \"../data/glove/glove.6B/glove.6B.50d.txt\"\n",
    "embedding_matrix = get_embedding_matrix(\n",
    "    tokenizer=tokenizer, path_glove=glove_path, embed_size=50, max_features=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM, Pooling and regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:51.383686Z",
     "start_time": "2018-01-17T13:41:50.552060Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(\n",
    "        max_features, embedding_matrix.shape[1], weights=[embedding_matrix]))\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:51.511008Z",
     "start_time": "2018-01-17T13:41:51.385668Z"
    }
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:51.547575Z",
     "start_time": "2018-01-17T13:41:51.512621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T13:41:51.557623Z",
     "start_time": "2018-01-17T13:41:51.549532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T14:23:15.854447Z",
     "start_time": "2018-01-17T13:41:51.559954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T14:23:16.047261Z",
     "start_time": "2018-01-17T14:23:15.857023Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('../data/work/complete_lstm_submission.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T14:31:23.085256Z",
     "start_time": "2018-01-17T14:23:16.049086Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = model.predict_proba(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T14:35:11.329793Z",
     "start_time": "2018-01-17T14:35:09.045206Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    predict, columns=targets,\n",
    "    index=df_test.id).reset_index().rename(columns={\n",
    "        \"index\": \"id\"\n",
    "    }).to_csv(\n",
    "        \"../submissions/complete_lstm_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
